{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Untitled23.ipynb","provenance":[{"file_id":"1liMdZvlAZFTiJ7810DnyjI8HrU29EqR0","timestamp":1594738621600}],"authorship_tag":"ABX9TyN8tH+yvm95YMho8B1KOlbS"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"Fy3K-OefLpPN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594728001495,"user_tz":-120,"elapsed":135125,"user":{"displayName":"Ryszard Tuora","photoUrl":"","userId":"14358185409280519443"}},"outputId":"0c67a312-6e34-46d5-c2e0-657bf33416d5"},"source":["!python3 -m pip install spacy==2.3.0\n","\n","\n","# instalacja oficjalnego modelu spaCy\n","!python3 -m spacy download pl_core_news_lg\n","\n","# dodatkowe zależności:\n","!python3 -m pip install tqdm\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting spacy==2.3.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/31/c7/e66e2af1cfa418c3a3917c116c4e00ccffa546f18f59e6acd7953d833c5c/spacy-2.3.0-cp36-cp36m-manylinux1_x86_64.whl (10.0MB)\n","\u001b[K     |████████████████████████████████| 10.0MB 2.7MB/s \n","\u001b[?25hRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy==2.3.0) (3.0.2)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy==2.3.0) (1.1.3)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy==2.3.0) (1.0.2)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.3.0) (2.23.0)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.3.0) (0.4.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy==2.3.0) (49.1.0)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.3.0) (0.7.0)\n","Collecting thinc==7.4.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/ae/ef3ae5e93639c0ef8e3eb32e3c18341e511b3c515fcfc603f4b808087651/thinc-7.4.1-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n","\u001b[K     |████████████████████████████████| 2.1MB 38.4MB/s \n","\u001b[?25hRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy==2.3.0) (2.0.3)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy==2.3.0) (1.0.0)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.3.0) (1.18.5)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.3.0) (4.41.1)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.3.0) (1.0.2)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.0) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.0) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.0) (2020.6.20)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy==2.3.0) (1.7.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy==2.3.0) (3.1.0)\n","Installing collected packages: thinc, spacy\n","  Found existing installation: thinc 7.4.0\n","    Uninstalling thinc-7.4.0:\n","      Successfully uninstalled thinc-7.4.0\n","  Found existing installation: spacy 2.2.4\n","    Uninstalling spacy-2.2.4:\n","      Successfully uninstalled spacy-2.2.4\n","Successfully installed spacy-2.3.0 thinc-7.4.1\n","Collecting pl_core_news_lg==2.3.0\n","\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/pl_core_news_lg-2.3.0/pl_core_news_lg-2.3.0.tar.gz (604.2MB)\n","\u001b[K     |████████████████████████████████| 604.2MB 1.2MB/s \n","\u001b[?25hRequirement already satisfied: spacy<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from pl_core_news_lg==2.3.0) (2.3.0)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->pl_core_news_lg==2.3.0) (1.18.5)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->pl_core_news_lg==2.3.0) (2.23.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->pl_core_news_lg==2.3.0) (49.1.0)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->pl_core_news_lg==2.3.0) (1.0.0)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->pl_core_news_lg==2.3.0) (0.7.0)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->pl_core_news_lg==2.3.0) (3.0.2)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->pl_core_news_lg==2.3.0) (1.1.3)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->pl_core_news_lg==2.3.0) (1.0.2)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->pl_core_news_lg==2.3.0) (0.4.1)\n","Requirement already satisfied: thinc==7.4.1 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->pl_core_news_lg==2.3.0) (7.4.1)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->pl_core_news_lg==2.3.0) (4.41.1)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->pl_core_news_lg==2.3.0) (1.0.2)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->pl_core_news_lg==2.3.0) (2.0.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->pl_core_news_lg==2.3.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->pl_core_news_lg==2.3.0) (2020.6.20)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->pl_core_news_lg==2.3.0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->pl_core_news_lg==2.3.0) (2.10)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->pl_core_news_lg==2.3.0) (1.7.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->pl_core_news_lg==2.3.0) (3.1.0)\n","Building wheels for collected packages: pl-core-news-lg\n","  Building wheel for pl-core-news-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pl-core-news-lg: filename=pl_core_news_lg-2.3.0-cp36-none-any.whl size=604232614 sha256=49036871256ac61bb7492efa425da3705b3cf48a0ba1d239bf2803a962fa60b8\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-b6738qmn/wheels/fb/60/e5/4e03ebc777d2bd26ac5394f00db1695bede7a92bc9e7ce1789\n","Successfully built pl-core-news-lg\n","Installing collected packages: pl-core-news-lg\n","Successfully installed pl-core-news-lg-2.3.0\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('pl_core_news_lg')\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.41.1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"KjCJu4Hi4zfK","colab_type":"text"},"source":["# Część szósta - Zastosowanie w filtrze cyberbullyingu\n","\n","Jednym z głównym zastosowań NLP, jest analiza wydźwięku (sentiment analysis) - automatyczna klasyfikacja tekstów (np. recenzji) ze względu na ich ładunek emocjonalny, wyrażoną ocenę, lub zawartość pewnego \"zabarwienia semantycznego\". W 2019 roku w PolEvalu, największym konkursie dotyczącym NLP dla języka polskiego, pojawiło się między innymi zadanie dotyczące automatycznej detekcji cyberbullyingu (http://2019.poleval.pl/index.php/tasks/task6).\n","\n","Skorzystamy z wbudowanych w model embeddingów, aby wytrenować sieć neuronową, służącą do klasyfikacji tweetów. Model będzie zrealizowany w ramach Kerasa, ale spaCy posiada także wbudowane API do tworzenia klasyfikatorów (TextClassifier)."]},{"cell_type":"code","metadata":{"id":"RSZezu6K55Xj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":612},"executionInfo":{"status":"ok","timestamp":1594728059593,"user_tz":-120,"elapsed":6164,"user":{"displayName":"Ryszard Tuora","photoUrl":"","userId":"14358185409280519443"}},"outputId":"e6a61d07-b573-456a-9a1c-c26854e11f5a"},"source":["# POBRANIE DANYCH\n","!wget http://2019.poleval.pl/task6/task_6-1.zip\n","!wget http://2019.poleval.pl/task6/task6_test.zip\n","!unzip task_6-1.zip\n","!unzip task6_test.zip"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2020-07-14 12:00:54--  http://2019.poleval.pl/task6/task_6-1.zip\n","Resolving 2019.poleval.pl (2019.poleval.pl)... 213.135.36.94\n","Connecting to 2019.poleval.pl (2019.poleval.pl)|213.135.36.94|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 339950 (332K) [application/zip]\n","Saving to: ‘task_6-1.zip’\n","\n","task_6-1.zip        100%[===================>] 331.98K   687KB/s    in 0.5s    \n","\n","2020-07-14 12:00:55 (687 KB/s) - ‘task_6-1.zip’ saved [339950/339950]\n","\n","--2020-07-14 12:00:56--  http://2019.poleval.pl/task6/task6_test.zip\n","Resolving 2019.poleval.pl (2019.poleval.pl)... 213.135.36.94\n","Connecting to 2019.poleval.pl (2019.poleval.pl)|213.135.36.94|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 70051 (68K) [application/zip]\n","Saving to: ‘task6_test.zip’\n","\n","task6_test.zip      100%[===================>]  68.41K   284KB/s    in 0.2s    \n","\n","2020-07-14 12:00:56 (284 KB/s) - ‘task6_test.zip’ saved [70051/70051]\n","\n","Archive:  task_6-1.zip\n","  inflating: training_set_clean_only_text.txt  \n","  inflating: training_set_clean_only_tags.txt  \n","Archive:  task6_test.zip\n","   creating: Task6/\n","   creating: Task6/task 01/\n","  inflating: Task6/task 01/evaulate1.pl  \n","  inflating: Task6/task 01/test_set_clean_only_tags.txt  \n","  inflating: Task6/task 01/test_set_clean_only_text.txt  \n","   creating: Task6/task 02/\n","  inflating: Task6/task 02/evaulate2.pl  \n","  inflating: Task6/task 02/test_set_only_tags.txt  \n","  inflating: Task6/task 02/test_set_only_text.txt  \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"R4X-Cs174ypN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":442},"executionInfo":{"status":"ok","timestamp":1594728245196,"user_tz":-120,"elapsed":140672,"user":{"displayName":"Ryszard Tuora","photoUrl":"","userId":"14358185409280519443"}},"outputId":"36948470-ffdb-46ef-abd6-8bcc1ae84dff"},"source":["import numpy\n","import random\n","import spacy\n","from keras.models import Sequential\n","from keras.layers import Dense, LSTM, Embedding, Masking, Dropout\n","from tqdm import tqdm\n","\n","# funkcje służące przygotowaniu reprezentacji danych\n","def get_embeddings(vocab):\n","    max_rank = max(lex.rank for lex in vocab if lex.has_vector)\n","    vectors = numpy.ndarray((max_rank+1, vocab.vectors_length), dtype='float32')\n","    for lex in vocab:\n","        if lex.has_vector:\n","            vectors[lex.rank] = lex.vector\n","    return vectors\n","\n","def get_features(docs, max_length):\n","    Xs = numpy.zeros((len(docs), max_length), dtype='int32')\n","    for i, doc in enumerate(docs):\n","        for j, token in enumerate(doc[:max_length]):\n","            Xs[i, j] = token.rank if token.has_vector else 0\n","    return Xs\n","\n","\n","# wczytywanie modelu\n","print(\"Ładowanie modelu.\\n\")\n","nlp = spacy.load(\"pl_core_news_lg\")\n","print(\"Załadowano model.\\n\")\n","print(\"\\n\")\n","\n","# wczytywanie danych\n","with open(\"training_set_clean_only_text.txt\") as f:\n","  txt = f.read()\n","  training_sents = txt.split(\"\\n\")[:-1]\n","\n","with open(\"training_set_clean_only_tags.txt\") as f:\n","  txt = f.read()\n","  training_labels = [int(x) for x in txt.split(\"\\n\")[:-1]]\n","\n","with open(\"Task6/task 01/test_set_clean_only_text.txt\") as f:\n","  txt = f.read()\n","  test_sents = txt.split(\"\\n\")[:-1]\n","\n","with open(\"Task6/task 01/test_set_clean_only_tags.txt\") as f:\n","  txt = f.read()\n","  test_labels = [int(x) for x in txt.split(\"\\n\")[:-1]]\n","\n","train_docs =[]\n","for x in tqdm(training_sents):\n","  train_docs.append(nlp(x))\n","dev_docs = []\n","for x in tqdm(test_sents):\n","  dev_docs.append(nlp(x))\n","max_len = max([len(d) for d in train_docs])\n","\n","print(\"\\nProporcja wyników dodatnich: {}\\n\".format(sum(training_labels)/len(training_labels)))\n","\n","# oversampling\n","pos_docs = []\n","for x, y in zip(train_docs, training_labels):\n","  if y == 1:\n","    pos_docs.append(x)\n","oversampling_x = 4*pos_docs\n","oversampling_y = [1 for x in oversampling_x]\n","train_docs.extend(oversampling_x)\n","training_labels.extend(oversampling_y)\n","indices = list(range(len(train_docs)))\n","random.shuffle(indices)\n","train_docs = [train_docs[i] for i in indices]\n","training_labels = [training_labels[i] for i in indices]\n","\n","# dane treningowe\n","train_X = get_features(train_docs, max_len)\n","train_Y = numpy.zeros((len(training_labels), 2))\n","for i, l in enumerate(training_labels):\n","  train_Y[i][l]=1\n","\n","# dane walidacyjne\n","dev_X = get_features(dev_docs, max_len)\n","dev_Y = numpy.zeros((len(test_labels), 2))\n","for i, l in enumerate(test_labels):\n","  dev_Y[i][l]=1\n","\n","for x, y in zip(train_docs[:10], training_labels[:10]):\n","  print(x, y)\n","print(\"\\nProporcja wyników dodatnich po oversamplingu: {}\\n\".format(sum(training_labels)/len(training_labels)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["Ładowanie modelu.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["  0%|          | 9/10041 [00:00<02:03, 80.97it/s]"],"name":"stderr"},{"output_type":"stream","text":["Załadowano model.\n","\n","\n","\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 10041/10041 [01:51<00:00, 89.82it/s]\n","100%|██████████| 1000/1000 [00:10<00:00, 92.54it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Proporcja wyników dodatnich: 0.08475251468977194\n","\n","@anonymized_account @anonymized_account Leczyć można z chorób - nie ze stanu umysłowego IQ :) 1\n","Cyyyyyk, mamy już zapis dzisiejszej Strefy Kibica z trenerem Ireneuszem Mamrotem. Zapraszamy do słuchania. 😊\\nhttps://t.co/RME1zo0xjz 0\n","Mojej mamie się śniło, że rozjechała mnie ciężarówka rip 0\n","@anonymized_account Przestań ćpać haszysz, jest życie poza marszem 1\n","@anonymized_account o widzisz, to nawet nie wiedziałam bo to było jakieś dwa lata temu 0\n","@anonymized_account Ciekawe w jaki sposób Nurowska okazuje panu profesorowi swoje poddaństwo. Pachnie mi tu sexem oralnym.😁😁😁😁 1\n","THIS IS WHY I LOVE THE INTERNET 😂😂😂\\n\\nhttps://t.co/obxKCqhOwH 0\n","@anonymized_account @anonymized_account @anonymized_account Pewnie z 12 mld całość, ale grosz do grosza 0\n","@anonymized_account @anonymized_account @anonymized_account Dekompozycja obozu rządzącego stała się faktem 0\n","@anonymized_account Jak pisdzielstwo 98% wymieniło to co się dziwisz parchu  , polaku złoty ptaku 1\n","\n","Proporcja wyników dodatnich po oversamplingu: 0.3164745258460394\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nji7fNKaAisJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":187},"executionInfo":{"status":"ok","timestamp":1594728461195,"user_tz":-120,"elapsed":212614,"user":{"displayName":"Ryszard Tuora","photoUrl":"","userId":"14358185409280519443"}},"outputId":"8c4f2dbc-9c3d-42d0-ce00-a4d34385e195"},"source":["# przygotowanie modelu Keras\n","embeddings = get_embeddings(nlp.vocab)\n","dim = 100\n","model = Sequential()\n","\n","model.add(\n","    Embedding(\n","        embeddings.shape[0],\n","        embeddings.shape[1],\n","        input_length=max_len,\n","        trainable=False,\n","        weights=[embeddings]\n","    )\n",")\n","model.add(Masking())\n","model.add(LSTM(dim))\n","model.add(Dense(2, activation=\"softmax\"))\n","model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics = [\"accuracy\"])\n","\n","\n","# trening klasyfikatora\n","model.fit(train_X, train_Y, validation_data=(dev_X,dev_Y), epochs = 4)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train on 13445 samples, validate on 1000 samples\n","Epoch 1/4\n","13445/13445 [==============================] - 54s 4ms/step - loss: 0.4842 - accuracy: 0.7633 - val_loss: 0.3409 - val_accuracy: 0.8490\n","Epoch 2/4\n","13445/13445 [==============================] - 51s 4ms/step - loss: 0.2969 - accuracy: 0.8759 - val_loss: 0.3628 - val_accuracy: 0.8480\n","Epoch 3/4\n","13445/13445 [==============================] - 52s 4ms/step - loss: 0.1886 - accuracy: 0.9283 - val_loss: 0.4487 - val_accuracy: 0.8720\n","Epoch 4/4\n","13445/13445 [==============================] - 51s 4ms/step - loss: 0.1248 - accuracy: 0.9560 - val_loss: 0.5185 - val_accuracy: 0.8640\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.callbacks.History at 0x7ff4ac0155f8>"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"A4UXpSirQs2n","colab_type":"text"},"source":["## Ewaluacja modelu:\n","W wypadku zadań klasyfikacyjnych binarnych, łatwo można zdefiniować i obliczyć następujące miary:\n","\n","**precision** (precyzja) - proporcja pozytywnych wyników z modelu, które zostały przypisane prawidłowo\n","\n","**recall** (czułość) - proporcja pozytywnych przykładów w danych, które zostały poprawnie wykryte\n","\n","**f1** - średnia harmoniczna precyzji i czułości"]},{"cell_type":"code","metadata":{"id":"7i28V4QQ_ig_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1594728614783,"user_tz":-120,"elapsed":1915,"user":{"displayName":"Ryszard Tuora","photoUrl":"","userId":"14358185409280519443"}},"outputId":"027a2521-f19b-407c-9841-0d512dfb8022"},"source":["# ewaluacja modelu\n","preds = model.predict_classes(dev_X)\n","TP, FP, TN, FN = 0, 0, 0, 0\n","for s,g in zip(preds, test_labels):\n","  if s == 1 and g == 1:\n","    TP +=1\n","  elif s ==1:\n","    FP +=1\n","  elif g ==1:\n","    FN +=1\n","  else:\n","    TN +=1\n","\n","precision = TP/(TP+FP)\n","recall = TP/(TP+FN)\n","f1 = 2* ((precision * recall)/(precision + recall))\n","print(\"precision: {}, recall: {}, f1: {}\".format(precision, recall, f1))\n","\n","test_example = \"To jest odrażające, nie wiem po co w ogóle żyjesz.\"\n","test_x = get_features([nlp(test_example)], max_len)\n","print(model.predict_classes(test_x)[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["precision: 0.4864864864864865, recall: 0.26865671641791045, f1: 0.3461538461538462\n","0\n"],"name":"stdout"}]}]}